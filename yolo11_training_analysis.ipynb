{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî¨ YOLOv11 Needle Defect Analysis & Training\n",
        "\n",
        "Ce notebook permet d'analyser le dataset restructur√© et d'entra√Æner un mod√®le YOLOv11 pour la d√©tection de d√©fauts sur des aiguilles.\n",
        "\n",
        "## Configuration des images\n",
        "- **Dimensions** : 1024√ó416 pixels (largeur √ó hauteur)\n",
        "- **Format** : YOLO segmentation\n",
        "- **Classes** : D√©fauts d√©tect√©s sur les aiguilles\n",
        "\n",
        "## Pipeline\n",
        "1. **Analyse du dataset** - Visualisation et statistiques\n",
        "2. **Validation des dimensions** - V√©rification des images\n",
        "3. **Entra√Ænement du mod√®le** - YOLOv11 segmentation\n",
        "4. **Validation et test** - √âvaluation des performances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import des biblioth√®ques n√©cessaires\n",
        "import os\n",
        "import json\n",
        "import yaml\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "from PIL import Image, ImageDraw\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s\")\n",
        "print(f\"   - PyTorch version: {torch.__version__}\")\n",
        "print(f\"   - CUDA disponible: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   - GPU: {torch.cuda.get_device_name()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration du projet\n",
        "DATASET_PATH = \"Restructured_Dataset\"  # Chemin vers le dataset restructur√©\n",
        "MODEL_NAME = \"yolo11n-seg.pt\"          # Mod√®le YOLOv11 (nano pour rapidit√©)\n",
        "EPOCHS = 100                           # Nombre d'√©poques d'entra√Ænement\n",
        "IMAGE_SIZE = (416, 1024)              # Dimensions des images (hauteur, largeur) - DO NOT CHANGE\n",
        "BATCH_SIZE = 8                        # Taille de batch (ajuster selon votre GPU)\n",
        "\n",
        "# Configuration des graines pour la reproductibilit√©\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "print(\"üîß Configuration du projet:\")\n",
        "print(f\"   - Dataset: {DATASET_PATH}\")\n",
        "print(f\"   - Mod√®le: {MODEL_NAME}\")\n",
        "print(f\"   - √âpoques: {EPOCHS}\")\n",
        "print(f\"   - Dimensions: {IMAGE_SIZE[1]}√ó{IMAGE_SIZE[0]} (largeur √ó hauteur)\")\n",
        "print(f\"   - Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   - Graine al√©atoire: {RANDOM_SEED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions de chargement des m√©tadonn√©es\n",
        "def load_metadata(dataset_path):\n",
        "    \"\"\"Load all metadata files\"\"\"\n",
        "    print(\"üìã Loading metadata...\")\n",
        "    \n",
        "    dataset_path = Path(dataset_path)\n",
        "    yolo_path = dataset_path / \"yolo_format\"\n",
        "    metadata_path = dataset_path / \"metadata\"\n",
        "    \n",
        "    # Load data.yaml\n",
        "    with open(yolo_path / \"data.yaml\", 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "    \n",
        "    # Load split assignment\n",
        "    with open(metadata_path / \"split_assignment.json\", 'r') as f:\n",
        "        split_assignment = json.load(f)\n",
        "    \n",
        "    # Load needle summary\n",
        "    with open(metadata_path / \"needle_summary.json\", 'r') as f:\n",
        "        needle_summary = json.load(f)\n",
        "    \n",
        "    # Load defect distribution\n",
        "    with open(metadata_path / \"defect_distribution.json\", 'r') as f:\n",
        "        defect_distribution = json.load(f)\n",
        "        \n",
        "    print(f\"‚úÖ Metadata loaded successfully\")\n",
        "    print(f\"   - Classes: {data_config['nc']}\")\n",
        "    print(f\"   - Train/Val/Test: {len(split_assignment['train'])}/{len(split_assignment['val'])}/{len(split_assignment['test'])} needles\")\n",
        "    \n",
        "    return data_config, split_assignment, needle_summary, defect_distribution\n",
        "\n",
        "print(\"‚úÖ Fonctions de chargement des m√©tadonn√©es d√©finies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 1: Charger les m√©tadonn√©es\n",
        "print(\"üìã Chargement des m√©tadonn√©es...\")\n",
        "data_config, split_assignment, needle_summary, defect_distribution = load_metadata(DATASET_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions de validation des dimensions\n",
        "def validate_image_dimensions(dataset_path, expected_size=(416, 1024)):\n",
        "    \"\"\"Validate that all images have the expected dimensions\"\"\"\n",
        "    print(f\"\\nüîç Validating image dimensions (expected: {expected_size[1]}x{expected_size[0]} - width x height)...\")\n",
        "    \n",
        "    dataset_path = Path(dataset_path)\n",
        "    yolo_path = dataset_path / \"yolo_format\"\n",
        "    \n",
        "    incorrect_images = []\n",
        "    total_images = 0\n",
        "    \n",
        "    for split in ['train', 'val', 'test']:\n",
        "        split_path = yolo_path / split / \"images\"\n",
        "        if split_path.exists():\n",
        "            for img_path in split_path.glob(\"*\"):\n",
        "                total_images += 1\n",
        "                try:\n",
        "                    # Load image to check dimensions\n",
        "                    img = cv2.imread(str(img_path))\n",
        "                    if img is not None:\n",
        "                        h, w = img.shape[:2]\n",
        "                        if (h, w) != expected_size:\n",
        "                            incorrect_images.append({\n",
        "                                'path': str(img_path),\n",
        "                                'actual': (w, h),\n",
        "                                'expected': (expected_size[1], expected_size[0])  # Convert to (width, height) for display\n",
        "                            })\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è  Error reading {img_path}: {e}\")\n",
        "    \n",
        "    if incorrect_images:\n",
        "        print(f\"‚ùå Found {len(incorrect_images)} images with incorrect dimensions:\")\n",
        "        for img_info in incorrect_images[:5]:  # Show first 5\n",
        "            print(f\"   {img_info['path']}: {img_info['actual']} (expected: {img_info['expected']})\")\n",
        "        if len(incorrect_images) > 5:\n",
        "            print(f\"   ... and {len(incorrect_images) - 5} more\")\n",
        "    else:\n",
        "        print(f\"‚úÖ All {total_images} images have correct dimensions!\")\n",
        "    \n",
        "    return len(incorrect_images) == 0\n",
        "\n",
        "print(\"‚úÖ Fonction de validation des dimensions d√©finie\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 2: Valider les dimensions des images\n",
        "print(\"üîç Validation des dimensions...\")\n",
        "validate_image_dimensions(DATASET_PATH, IMAGE_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions d'analyse et de visualisation\n",
        "def analyze_dataset_distribution(split_assignment, needle_summary):\n",
        "    \"\"\"Analyze and visualize dataset distribution\"\"\"\n",
        "    print(\"\\nüìä Analyzing dataset distribution...\")\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle('Dataset Distribution Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Split distribution (needles)\n",
        "    split_counts = {split: len(needles) for split, needles in split_assignment.items()}\n",
        "    axes[0, 0].pie(split_counts.values(), labels=split_counts.keys(), autopct='%1.1f%%', startangle=90)\n",
        "    axes[0, 0].set_title('Dataset Split (Needles)')\n",
        "    \n",
        "    # 2. Images per split\n",
        "    split_image_counts = {}\n",
        "    for split, needles in split_assignment.items():\n",
        "        total_images = sum(needle_summary[needle]['image_count'] for needle in needles if needle in needle_summary)\n",
        "        split_image_counts[split] = total_images\n",
        "    \n",
        "    axes[0, 1].bar(split_image_counts.keys(), split_image_counts.values(), color=['#FF9999', '#66B2FF', '#99FF99'])\n",
        "    axes[0, 1].set_title('Total Images per Split')\n",
        "    axes[0, 1].set_ylabel('Number of Images')\n",
        "    \n",
        "    # 3. Defect distribution across splits\n",
        "    defect_split_data = defaultdict(lambda: {'train': 0, 'val': 0, 'test': 0})\n",
        "    \n",
        "    for split, needles in split_assignment.items():\n",
        "        for needle in needles:\n",
        "            if needle in needle_summary:\n",
        "                defect_types = needle_summary[needle]['defect_types']\n",
        "                if defect_types:\n",
        "                    main_defect = defect_types[0]  # Use first defect as main\n",
        "                    defect_split_data[main_defect][split] += 1\n",
        "    \n",
        "    # Convert to DataFrame for easier plotting\n",
        "    defect_df = pd.DataFrame(defect_split_data).T.fillna(0)\n",
        "    defect_df.plot(kind='bar', ax=axes[1, 0], stacked=True)\n",
        "    axes[1, 0].set_title('Defect Distribution Across Splits')\n",
        "    axes[1, 0].set_xlabel('Defect Class ID')\n",
        "    axes[1, 0].set_ylabel('Number of Needles')\n",
        "    axes[1, 0].legend(title='Split')\n",
        "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # 4. Visible defects per needle distribution\n",
        "    visible_counts = [needle_summary[needle]['visible_defects_count'] \n",
        "                     for needle in needle_summary.keys()]\n",
        "    axes[1, 1].hist(visible_counts, bins=max(1, max(visible_counts)), alpha=0.7, edgecolor='black')\n",
        "    axes[1, 1].set_title('Distribution of Visible Defects per Needle')\n",
        "    axes[1, 1].set_xlabel('Number of Visible Defects')\n",
        "    axes[1, 1].set_ylabel('Number of Needles')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print summary statistics\n",
        "    print(f\"\\nüìà Summary Statistics:\")\n",
        "    print(f\"   Total needles: {sum(split_counts.values())}\")\n",
        "    print(f\"   Total images: {sum(split_image_counts.values())}\")\n",
        "    print(f\"   Images with defects: {sum(needle_summary[n]['visible_defects_count'] for n in needle_summary)}\")\n",
        "    print(f\"   Average images per needle: {sum(split_image_counts.values()) / sum(split_counts.values()):.1f}\")\n",
        "\n",
        "print(\"‚úÖ Fonction d'analyse de distribution d√©finie\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 3: Analyser la distribution du dataset\n",
        "print(\"üìä Analyse de la distribution...\")\n",
        "analyze_dataset_distribution(split_assignment, needle_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions de visualisation des √©chantillons\n",
        "def parse_yolo_label(label_path):\n",
        "    \"\"\"Parse YOLO segmentation label file\"\"\"\n",
        "    annotations = []\n",
        "    try:\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    parts = line.split()\n",
        "                    if len(parts) >= 6:  # At least class + 2 points (x1,y1,x2,y2)\n",
        "                        class_id = int(parts[0])\n",
        "                        # Parse polygon points (normalized coordinates)\n",
        "                        points = [float(x) for x in parts[1:]]\n",
        "                        # Group points as (x,y) pairs\n",
        "                        polygon = [(points[i], points[i+1]) for i in range(0, len(points), 2)]\n",
        "                        annotations.append({'class_id': class_id, 'polygon': polygon})\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error parsing {label_path}: {e}\")\n",
        "    return annotations\n",
        "\n",
        "def visualize_samples(dataset_path, data_config, num_samples=6, split='train'):\n",
        "    \"\"\"Visualize random samples from the dataset\"\"\"\n",
        "    print(f\"\\nüñºÔ∏è  Visualizing {num_samples} samples from {split} set...\")\n",
        "    \n",
        "    dataset_path = Path(dataset_path)\n",
        "    yolo_path = dataset_path / \"yolo_format\"\n",
        "    split_path = yolo_path / split\n",
        "    image_files = list((split_path / \"images\").glob(\"*\"))\n",
        "    \n",
        "    # Select random samples\n",
        "    if len(image_files) < num_samples:\n",
        "        num_samples = len(image_files)\n",
        "        print(f\"‚ö†Ô∏è  Only {num_samples} images available in {split} set\")\n",
        "    \n",
        "    selected_files = random.sample(image_files, num_samples)\n",
        "    \n",
        "    # Create subplot grid\n",
        "    cols = 3\n",
        "    rows = (num_samples + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
        "    if rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    class_names = data_config['names']\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(class_names)))\n",
        "    \n",
        "    for idx, img_path in enumerate(selected_files):\n",
        "        row, col = idx // cols, idx % cols\n",
        "        \n",
        "        # Load image\n",
        "        image = cv2.imread(str(img_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        h, w = image.shape[:2]\n",
        "        \n",
        "        # Load corresponding label\n",
        "        label_path = split_path / \"labels\" / f\"{img_path.stem}.txt\"\n",
        "        annotations = parse_yolo_label(label_path)\n",
        "        \n",
        "        # Draw annotations\n",
        "        img_with_annotations = image.copy()\n",
        "        for ann in annotations:\n",
        "            class_id = ann['class_id']\n",
        "            polygon = ann['polygon']\n",
        "            \n",
        "            # Convert normalized coordinates to pixel coordinates\n",
        "            pixel_polygon = [(int(x * w), int(y * h)) for x, y in polygon]\n",
        "            \n",
        "            # Draw polygon\n",
        "            if len(pixel_polygon) >= 3:\n",
        "                pts = np.array(pixel_polygon, np.int32)\n",
        "                pts = pts.reshape((-1, 1, 2))\n",
        "                \n",
        "                # Fill polygon with transparency\n",
        "                overlay = img_with_annotations.copy()\n",
        "                cv2.fillPoly(overlay, [pts], colors[class_id % len(colors)] * 255)\n",
        "                img_with_annotations = cv2.addWeighted(img_with_annotations, 0.7, overlay, 0.3, 0)\n",
        "                \n",
        "                # Draw polygon outline\n",
        "                cv2.polylines(img_with_annotations, [pts], True, colors[class_id % len(colors)] * 255, 2)\n",
        "                \n",
        "                # Add class label\n",
        "                if pixel_polygon:\n",
        "                    center_x = int(np.mean([p[0] for p in pixel_polygon]))\n",
        "                    center_y = int(np.mean([p[1] for p in pixel_polygon]))\n",
        "                    label_text = f\"{class_names[class_id] if class_id < len(class_names) else f'Class_{class_id}'}\"\n",
        "                    cv2.putText(img_with_annotations, label_text, (center_x-30, center_y),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "        \n",
        "        # Display\n",
        "        axes[row, col].imshow(img_with_annotations)\n",
        "        axes[row, col].set_title(f\"{img_path.name}\\n{len(annotations)} defects\", fontsize=10)\n",
        "        axes[row, col].axis('off')\n",
        "    \n",
        "    # Hide empty subplots\n",
        "    for idx in range(num_samples, rows * cols):\n",
        "        row, col = idx // cols, idx % cols\n",
        "        axes[row, col].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"‚úÖ Fonctions de visualisation des √©chantillons d√©finies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 4: Visualiser des √©chantillons du dataset\n",
        "print(\"üñºÔ∏è Visualisation des √©chantillons d'entra√Ænement...\")\n",
        "visualize_samples(DATASET_PATH, data_config, num_samples=6, split='train')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 5: Visualiser des √©chantillons de validation\n",
        "print(\"üñºÔ∏è Visualisation des √©chantillons de validation...\")\n",
        "visualize_samples(DATASET_PATH, data_config, num_samples=4, split='val')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions d'entra√Ænement YOLO\n",
        "def setup_model(model_name):\n",
        "    \"\"\"Initialize YOLO model\"\"\"\n",
        "    print(f\"ü§ñ Setting up YOLO model: {model_name}\")\n",
        "    model = YOLO(model_name)\n",
        "    print(f\"‚úÖ Model loaded successfully\")\n",
        "    return model\n",
        "\n",
        "def train_model(data_yaml, model, epochs, imgsz, batch_size, patience=50, **kwargs):\n",
        "    \"\"\"Train YOLO model\"\"\"\n",
        "    print(f\"üöÄ Starting training...\")\n",
        "    print(f\"   - Epochs: {epochs}\")\n",
        "    print(f\"   - Image size: {imgsz}\")\n",
        "    print(f\"   - Batch size: {batch_size}\")\n",
        "    print(f\"   - Patience: {patience}\")\n",
        "    \n",
        "    # Training parameters\n",
        "    train_args = {\n",
        "        'data': data_yaml,\n",
        "        'epochs': epochs,\n",
        "        'imgsz': imgsz,\n",
        "        'batch': batch_size,\n",
        "        'patience': patience,\n",
        "        'save': True,\n",
        "        'save_period': 10,\n",
        "        'cache': True,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'workers': 4,\n",
        "        'project': 'runs/train',\n",
        "        'name': 'yolo11_needle_defect',\n",
        "        **kwargs\n",
        "    }\n",
        "    \n",
        "    # Start training\n",
        "    results = model.train(**train_args)\n",
        "    \n",
        "    print(f\"‚úÖ Training completed!\")\n",
        "    return results\n",
        "\n",
        "def validate_model(data_yaml, model):\n",
        "    \"\"\"Validate the trained model\"\"\"\n",
        "    print(f\"üîç Validating model...\")\n",
        "    \n",
        "    # Run validation\n",
        "    val_results = model.val(data=data_yaml)\n",
        "    \n",
        "    print(f\"‚úÖ Validation completed!\")\n",
        "    print(f\"   - mAP50: {val_results.box.map50:.3f}\")\n",
        "    print(f\"   - mAP50-95: {val_results.box.map:.3f}\")\n",
        "    \n",
        "    return val_results\n",
        "\n",
        "print(\"‚úÖ Fonctions d'entra√Ænement YOLO d√©finies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 6: Initialiser le mod√®le YOLO\n",
        "print(\"ü§ñ Initialisation du mod√®le...\")\n",
        "model = setup_model(MODEL_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 7: Entra√Æner le mod√®le\n",
        "print(\"üöÄ D√©marrage de l'entra√Ænement...\")\n",
        "data_yaml_path = str(Path(DATASET_PATH) / \"yolo_format\" / \"data.yaml\")\n",
        "results = train_model(data_yaml_path, model, EPOCHS, IMAGE_SIZE, BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 8: Valider le mod√®le entra√Æn√©\n",
        "print(\"üîç Validation du mod√®le...\")\n",
        "val_results = validate_model(data_yaml_path, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions de test et d'inf√©rence\n",
        "def test_inference(data_yaml, model, test_images, conf=0.25, save_results=True):\n",
        "    \"\"\"Test model inference on sample images\"\"\"\n",
        "    print(f\"üîç Testing inference on {len(test_images)} images...\")\n",
        "    \n",
        "    results = []\n",
        "    for img_path in test_images:\n",
        "        # Run inference\n",
        "        result = model.predict(img_path, conf=conf, save=save_results)\n",
        "        results.append(result)\n",
        "        \n",
        "        # Print results\n",
        "        if result[0].boxes is not None:\n",
        "            num_detections = len(result[0].boxes)\n",
        "            print(f\"   {img_path.name}: {num_detections} defects detected\")\n",
        "        else:\n",
        "            print(f\"   {img_path.name}: No defects detected\")\n",
        "    \n",
        "    print(f\"‚úÖ Inference testing completed!\")\n",
        "    return results\n",
        "\n",
        "print(\"‚úÖ Fonctions de test et d'inf√©rence d√©finies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 9: Tester l'inf√©rence sur des images de test\n",
        "print(\"üîç Test d'inf√©rence sur des images de test...\")\n",
        "test_images_path = Path(DATASET_PATH) / \"yolo_format\" / \"test\" / \"images\"\n",
        "test_images = list(test_images_path.glob(\"*\"))[:5]  # Prendre les 5 premi√®res images de test\n",
        "\n",
        "if test_images:\n",
        "    inference_results = test_inference(data_yaml_path, model, test_images)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Aucune image de test trouv√©e!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
