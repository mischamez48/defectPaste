{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîß YOLO Dataset Restructurer\n",
        "\n",
        "Ce notebook permet de restructurer un dataset d'images d'aiguilles avec annotations YOLO pour l'entra√Ænement.\n",
        "\n",
        "## Structure attendue en entr√©e :\n",
        "```\n",
        "Dataset/\n",
        "‚îú‚îÄ‚îÄ Images/          # Images des aiguilles\n",
        "‚îî‚îÄ‚îÄ Labels/          # Fichiers .txt avec annotations YOLO\n",
        "```\n",
        "\n",
        "## Structure g√©n√©r√©e :\n",
        "```\n",
        "Restructured_Dataset/\n",
        "‚îú‚îÄ‚îÄ metadata/         # Fichiers JSON avec statistiques\n",
        "‚îú‚îÄ‚îÄ organized_by_needle/  # Organisation par aiguille\n",
        "‚îî‚îÄ‚îÄ yolo_format/      # Format standard YOLO\n",
        "    ‚îú‚îÄ‚îÄ train/images & labels\n",
        "    ‚îú‚îÄ‚îÄ val/images & labels\n",
        "    ‚îî‚îÄ‚îÄ test/images & labels\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import des biblioth√®ques n√©cessaires\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration des chemins\n",
        "ORIGINAL_DATASET_PATH = \"Dataset\"  # Votre dataset actuel\n",
        "OUTPUT_PATH = \"Restructured_Dataset\"  # O√π cr√©er la nouvelle structure\n",
        "\n",
        "# Ratios de division (train/val/test)\n",
        "TRAIN_RATIO = 0.75   # 75% pour l'entra√Ænement\n",
        "VAL_RATIO = 0.15     # 15% pour la validation  \n",
        "TEST_RATIO = 0.10    # 10% pour les tests\n",
        "\n",
        "print(f\"üìÅ Configuration:\")\n",
        "print(f\"   - Dataset original: {ORIGINAL_DATASET_PATH}\")\n",
        "print(f\"   - Sortie: {OUTPUT_PATH}\")\n",
        "print(f\"   - Division: {TRAIN_RATIO:.0%}/{VAL_RATIO:.0%}/{TEST_RATIO:.0%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions utilitaires\n",
        "def extract_needle_id(filename):\n",
        "    \"\"\"Extract needle ID from filename (AIG1, AIG2, etc.)\"\"\"\n",
        "    match = re.match(r'(AIG\\\\d+)', filename)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def find_corresponding_image(label_stem, images_path):\n",
        "    \"\"\"Find corresponding image file for a label\"\"\"\n",
        "    possible_extensions = ['.png', '.jpg', '.jpeg']\n",
        "    for ext in possible_extensions:\n",
        "        image_path = images_path / f\"{label_stem}{ext}\"\n",
        "        if image_path.exists():\n",
        "            return image_path\n",
        "    return None\n",
        "\n",
        "def parse_label_file(label_path):\n",
        "    \"\"\"Parse YOLO label file and extract defect types\"\"\"\n",
        "    defect_types = set()\n",
        "    try:\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if line:  # Non-empty line\n",
        "                    parts = line.split()\n",
        "                    if parts:\n",
        "                        defect_type = int(parts[0])  # First element is class ID\n",
        "                        defect_types.add(defect_type)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error reading {label_path}: {e}\")\n",
        "    return defect_types\n",
        "\n",
        "print(\"‚úÖ Fonctions utilitaires d√©finies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test des fonctions utilitaires (optionnel)\n",
        "# D√©commentez les lignes suivantes pour tester\n",
        "# test_filename = \"AIG1_image_001\"\n",
        "# needle_id = extract_needle_id(test_filename)\n",
        "# print(f\"Needle ID extrait: {needle_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions d'analyse du dataset\n",
        "def analyze_dataset(original_dataset_path):\n",
        "    \"\"\"Analyze the current dataset structure and defect distribution\"\"\"\n",
        "    print(\"üîç Analyzing dataset...\")\n",
        "    \n",
        "    original_path = Path(original_dataset_path)\n",
        "    images_path = original_path / \"Images\"\n",
        "    labels_path = original_path / \"Labels\"\n",
        "    \n",
        "    # Get all label files\n",
        "    label_files = list(labels_path.glob(\"*.txt\"))\n",
        "    \n",
        "    needle_data = {}\n",
        "    defect_stats = defaultdict(list)\n",
        "    \n",
        "    for label_file in label_files:\n",
        "        needle_id = extract_needle_id(label_file.stem)\n",
        "        \n",
        "        if needle_id not in needle_data:\n",
        "            needle_data[needle_id] = {\n",
        "                'images': [],\n",
        "                'labels': [],\n",
        "                'defect_types': set(),\n",
        "                'visible_defects_count': 0\n",
        "            }\n",
        "        \n",
        "        # Check corresponding image\n",
        "        image_file = find_corresponding_image(label_file.stem, images_path)\n",
        "        if image_file:\n",
        "            needle_data[needle_id]['images'].append(image_file)\n",
        "            needle_data[needle_id]['labels'].append(label_file)\n",
        "            \n",
        "            # Parse label file for defect types\n",
        "            defect_types = parse_label_file(label_file)\n",
        "            if defect_types:  # Non-empty label\n",
        "                needle_data[needle_id]['defect_types'].update(defect_types)\n",
        "                needle_data[needle_id]['visible_defects_count'] += 1\n",
        "    \n",
        "    # Aggregate defect statistics\n",
        "    for needle_id, data in needle_data.items():\n",
        "        if data['defect_types']:\n",
        "            main_defect = list(data['defect_types'])[0]  # Take first defect as main\n",
        "            defect_stats[main_defect].append(needle_id)\n",
        "    \n",
        "    print_analysis_results(needle_data, defect_stats)\n",
        "    return needle_data, defect_stats\n",
        "\n",
        "def print_analysis_results(needle_data, defect_stats):\n",
        "    \"\"\"Print analysis results\"\"\"\n",
        "    print(f\"\\\\nüìä Dataset Analysis Results:\")\n",
        "    print(f\"Total needles found: {len(needle_data)}\")\n",
        "    \n",
        "    total_images = sum(len(data['images']) for data in needle_data.values())\n",
        "    total_with_defects = sum(data['visible_defects_count'] for data in needle_data.values())\n",
        "    \n",
        "    print(f\"Total images: {total_images}\")\n",
        "    print(f\"Images with visible defects: {total_with_defects}\")\n",
        "    print(f\"Images without defects: {total_images - total_with_defects}\")\n",
        "    \n",
        "    print(f\"\\\\nüè∑Ô∏è  Defect Distribution:\")\n",
        "    defect_counts = {defect: len(needles) for defect, needles in defect_stats.items()}\n",
        "    for defect_id, count in sorted(defect_counts.items()):\n",
        "        print(f\"  Class {defect_id}: {count} needles\")\n",
        "    \n",
        "    print(f\"\\\\nüìà Needles by visible defect count:\")\n",
        "    visible_counts = Counter(data['visible_defects_count'] for data in needle_data.values())\n",
        "    for count, needles in sorted(visible_counts.items()):\n",
        "        print(f\"  {count} visible defects: {needles} needles\")\n",
        "\n",
        "print(\"‚úÖ Fonctions d'analyse d√©finies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 1: Analyser le dataset\n",
        "print(\"üîç Analyse du dataset...\")\n",
        "needle_data, defect_stats = analyze_dataset(ORIGINAL_DATASET_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions de division stratifi√©e\n",
        "def create_stratified_split(needle_data, train_ratio=0.75, val_ratio=0.15, test_ratio=0.10):\n",
        "    \"\"\"Create stratified split ensuring balanced defect distribution\"\"\"\n",
        "    print(f\"\\\\nüéØ Creating stratified split ({train_ratio:.0%}/{val_ratio:.0%}/{test_ratio:.0%})...\")\n",
        "    \n",
        "    # Group needles by their main defect type\n",
        "    defect_groups = {}\n",
        "    needles_without_defects = []\n",
        "    \n",
        "    for needle_id, data in needle_data.items():\n",
        "        if data['defect_types']:\n",
        "            main_defect = list(data['defect_types'])[0]  # Use first defect as main\n",
        "            if main_defect not in defect_groups:\n",
        "                defect_groups[main_defect] = []\n",
        "            defect_groups[main_defect].append(needle_id)\n",
        "        else:\n",
        "            needles_without_defects.append(needle_id)\n",
        "    \n",
        "    train_needles = []\n",
        "    val_needles = []\n",
        "    test_needles = []\n",
        "    \n",
        "    # Split each defect group proportionally\n",
        "    for defect_id, needles in defect_groups.items():\n",
        "        if len(needles) == 1:\n",
        "            # Single needle goes to train\n",
        "            train_needles.extend(needles)\n",
        "        elif len(needles) == 2:\n",
        "            # Two needles: one to train, one to val\n",
        "            train_needles.append(needles[0])\n",
        "            val_needles.append(needles[1])\n",
        "        else:\n",
        "            # Multiple needles: stratified split\n",
        "            n_train = max(1, int(len(needles) * train_ratio))\n",
        "            n_val = max(1, int(len(needles) * val_ratio))\n",
        "            \n",
        "            train_split = needles[:n_train]\n",
        "            val_split = needles[n_train:n_train + n_val]\n",
        "            test_split = needles[n_train + n_val:]\n",
        "            \n",
        "            train_needles.extend(train_split)\n",
        "            val_needles.extend(val_split)\n",
        "            test_needles.extend(test_split)\n",
        "    \n",
        "    # Handle needles without visible defects\n",
        "    if needles_without_defects:\n",
        "        if len(needles_without_defects) == 1:\n",
        "            train_needles.extend(needles_without_defects)\n",
        "        else:\n",
        "            n_train = max(1, int(len(needles_without_defects) * train_ratio))\n",
        "            n_val = max(0, int(len(needles_without_defects) * val_ratio))\n",
        "            \n",
        "            train_split = needles_without_defects[:n_train]\n",
        "            val_split = needles_without_defects[n_train:n_train + n_val]\n",
        "            test_split = needles_without_defects[n_train + n_val:]\n",
        "            \n",
        "            train_needles.extend(train_split)\n",
        "            val_needles.extend(val_split)\n",
        "            test_needles.extend(test_split)\n",
        "    \n",
        "    split_assignment = {\n",
        "        'train': sorted(train_needles),\n",
        "        'val': sorted(val_needles),\n",
        "        'test': sorted(test_needles)\n",
        "    }\n",
        "    \n",
        "    print_split_results(split_assignment, needle_data)\n",
        "    return split_assignment\n",
        "\n",
        "def print_split_results(split_assignment, needle_data):\n",
        "    \"\"\"Print split results with defect distribution\"\"\"\n",
        "    print(f\"\\\\nüìã Split Results:\")\n",
        "    \n",
        "    for split_name, needles in split_assignment.items():\n",
        "        print(f\"\\\\n{split_name.upper()}:\")\n",
        "        print(f\"  Needles: {len(needles)}\")\n",
        "        \n",
        "        # Count images and defects per split\n",
        "        total_images = 0\n",
        "        total_with_defects = 0\n",
        "        defect_distribution = defaultdict(int)\n",
        "        \n",
        "        for needle_id in needles:\n",
        "            if needle_id in needle_data:\n",
        "                data = needle_data[needle_id]\n",
        "                total_images += len(data['images'])\n",
        "                total_with_defects += data['visible_defects_count']\n",
        "                \n",
        "                if data['defect_types']:\n",
        "                    main_defect = list(data['defect_types'])[0]\n",
        "                    defect_distribution[main_defect] += 1\n",
        "        \n",
        "        print(f\"  Total images: {total_images}\")\n",
        "        print(f\"  Images with defects: {total_with_defects}\")\n",
        "        print(f\"  Defect distribution: {dict(defect_distribution)}\")\n",
        "\n",
        "print(\"‚úÖ Fonctions de division stratifi√©e d√©finies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 2: Cr√©er la division stratifi√©e\n",
        "print(\"üéØ Cr√©ation de la division stratifi√©e...\")\n",
        "split_assignment = create_stratified_split(needle_data, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions de cr√©ation de structure et copie de fichiers\n",
        "def create_directory_structure(output_path, needle_data):\n",
        "    \"\"\"Create the new directory structure\"\"\"\n",
        "    print(f\"\\\\nüìÅ Creating directory structure at {output_path}...\")\n",
        "    \n",
        "    output_path = Path(output_path)\n",
        "    \n",
        "    # Create main directories\n",
        "    directories = [\n",
        "        \"metadata\",\n",
        "        \"organized_by_needle\",\n",
        "        \"yolo_format/train/images\",\n",
        "        \"yolo_format/train/labels\", \n",
        "        \"yolo_format/val/images\",\n",
        "        \"yolo_format/val/labels\",\n",
        "        \"yolo_format/test/images\",\n",
        "        \"yolo_format/test/labels\"\n",
        "    ]\n",
        "    \n",
        "    for directory in directories:\n",
        "        (output_path / directory).mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Create needle-specific directories\n",
        "    for needle_id in needle_data.keys():\n",
        "        needle_dir = output_path / \"organized_by_needle\" / needle_id\n",
        "        (needle_dir / \"images\").mkdir(parents=True, exist_ok=True)\n",
        "        (needle_dir / \"labels\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def copy_files(output_path, needle_data, split_assignment):\n",
        "    \"\"\"Copy files to new structure\"\"\"\n",
        "    print(f\"\\\\nüìã Copying files...\")\n",
        "    \n",
        "    output_path = Path(output_path)\n",
        "    \n",
        "    # Copy to organized_by_needle structure\n",
        "    for needle_id, data in needle_data.items():\n",
        "        needle_dir = output_path / \"organized_by_needle\" / needle_id\n",
        "        \n",
        "        # Copy images\n",
        "        for image_path in data['images']:\n",
        "            shutil.copy2(image_path, needle_dir / \"images\" / image_path.name)\n",
        "        \n",
        "        # Copy labels\n",
        "        for label_path in data['labels']:\n",
        "            shutil.copy2(label_path, needle_dir / \"labels\" / label_path.name)\n",
        "    \n",
        "    # Copy to YOLO format structure\n",
        "    for split_name, needles in split_assignment.items():\n",
        "        split_dir = output_path / \"yolo_format\" / split_name\n",
        "        \n",
        "        for needle_id in needles:\n",
        "            if needle_id in needle_data:\n",
        "                data = needle_data[needle_id]\n",
        "                \n",
        "                # Copy images\n",
        "                for image_path in data['images']:\n",
        "                    shutil.copy2(image_path, split_dir / \"images\" / image_path.name)\n",
        "                \n",
        "                # Copy labels  \n",
        "                for label_path in data['labels']:\n",
        "                    shutil.copy2(label_path, split_dir / \"labels\" / label_path.name)\n",
        "\n",
        "print(\"‚úÖ Fonctions de cr√©ation de structure et copie d√©finies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 3: Cr√©er la structure de r√©pertoires\n",
        "print(\"üìÅ Cr√©ation de la structure de r√©pertoires...\")\n",
        "create_directory_structure(OUTPUT_PATH, needle_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 4: Copier les fichiers\n",
        "print(\"üìã Copie des fichiers...\")\n",
        "copy_files(OUTPUT_PATH, needle_data, split_assignment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions de sauvegarde des m√©tadonn√©es\n",
        "def save_metadata(output_path, needle_data, defect_stats, split_assignment):\n",
        "    \"\"\"Save metadata files\"\"\"\n",
        "    print(f\"\\\\nüíæ Saving metadata...\")\n",
        "    \n",
        "    output_path = Path(output_path)\n",
        "    metadata_dir = output_path / \"metadata\"\n",
        "    \n",
        "    # Save needle data\n",
        "    needle_summary = {}\n",
        "    for needle_id, data in needle_data.items():\n",
        "        needle_summary[needle_id] = {\n",
        "            'image_count': len(data['images']),\n",
        "            'visible_defects_count': data['visible_defects_count'],\n",
        "            'defect_types': list(data['defect_types'])\n",
        "        }\n",
        "    \n",
        "    with open(metadata_dir / \"needle_summary.json\", 'w') as f:\n",
        "        json.dump(needle_summary, f, indent=2)\n",
        "    \n",
        "    # Save defect distribution\n",
        "    defect_distribution = {str(k): v for k, v in defect_stats.items()}\n",
        "    with open(metadata_dir / \"defect_distribution.json\", 'w') as f:\n",
        "        json.dump(defect_distribution, f, indent=2)\n",
        "    \n",
        "    # Save split assignment\n",
        "    with open(metadata_dir / \"split_assignment.json\", 'w') as f:\n",
        "        json.dump(split_assignment, f, indent=2)\n",
        "    \n",
        "    # Create data.yaml for YOLO\n",
        "    create_data_yaml(output_path, needle_data, split_assignment)\n",
        "\n",
        "def create_data_yaml(output_path, needle_data, split_assignment):\n",
        "    \"\"\"Create data.yaml file for YOLO training\"\"\"\n",
        "    output_path = Path(output_path)\n",
        "    \n",
        "    # Get all unique defect classes\n",
        "    all_defects = set()\n",
        "    for data in needle_data.values():\n",
        "        all_defects.update(data['defect_types'])\n",
        "    \n",
        "    # Create class names (you may want to customize these)\n",
        "    class_names = {i: f\"defect_{i}\" for i in sorted(all_defects)}\n",
        "    \n",
        "    yaml_content = f\"\"\"# YOLOv11 Dataset Configuration\n",
        "# Generated automatically\n",
        "\n",
        "path: {output_path / 'yolo_format'}  # dataset root dir\n",
        "train: train/images  # train images (relative to 'path')\n",
        "val: val/images      # val images (relative to 'path')\n",
        "test: test/images    # test images (relative to 'path')\n",
        "\n",
        "# Classes\n",
        "nc: {len(class_names)}  # number of classes\n",
        "names: {list(class_names.values())}  # class names\n",
        "\n",
        "# Additional info\n",
        "total_needles: {len(needle_data)}\n",
        "train_needles: {len(split_assignment.get('train', []))}\n",
        "val_needles: {len(split_assignment.get('val', []))}\n",
        "test_needles: {len(split_assignment.get('test', []))}\n",
        "\"\"\"\n",
        "    \n",
        "    with open(output_path / \"yolo_format\" / \"data.yaml\", 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "    \n",
        "    print(f\"‚úÖ Created data.yaml with {len(class_names)} classes\")\n",
        "\n",
        "print(\"‚úÖ Fonctions de sauvegarde des m√©tadonn√©es d√©finies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 5: Sauvegarder les m√©tadonn√©es\n",
        "print(\"üíæ Sauvegarde des m√©tadonn√©es...\")\n",
        "save_metadata(OUTPUT_PATH, needle_data, defect_stats, split_assignment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction de v√©rification des r√©sultats\n",
        "def check_directory_structure(base_path):\n",
        "    \"\"\"V√©rifier la structure des r√©pertoires cr√©√©s\"\"\"\n",
        "    print(f\"üìÅ V√©rification de la structure dans {base_path}:\")\n",
        "    \n",
        "    if not os.path.exists(base_path):\n",
        "        print(f\"‚ùå Le r√©pertoire {base_path} n'existe pas!\")\n",
        "        return\n",
        "    \n",
        "    # V√©rifier les r√©pertoires principaux\n",
        "    main_dirs = [\"metadata\", \"organized_by_needle\", \"yolo_format\"]\n",
        "    for dir_name in main_dirs:\n",
        "        dir_path = os.path.join(base_path, dir_name)\n",
        "        if os.path.exists(dir_path):\n",
        "            print(f\"‚úÖ {dir_name}/\")\n",
        "        else:\n",
        "            print(f\"‚ùå {dir_name}/ manquant\")\n",
        "    \n",
        "    # V√©rifier la structure YOLO\n",
        "    yolo_dirs = [\"yolo_format/train/images\", \"yolo_format/train/labels\",\n",
        "                 \"yolo_format/val/images\", \"yolo_format/val/labels\",\n",
        "                 \"yolo_format/test/images\", \"yolo_format/test/labels\"]\n",
        "    \n",
        "    print(f\"\\\\nüìã Structure YOLO:\")\n",
        "    for dir_name in yolo_dirs:\n",
        "        dir_path = os.path.join(base_path, dir_name)\n",
        "        if os.path.exists(dir_path):\n",
        "            file_count = len(os.listdir(dir_path))\n",
        "            print(f\"‚úÖ {dir_name}/ ({file_count} fichiers)\")\n",
        "        else:\n",
        "            print(f\"‚ùå {dir_name}/ manquant\")\n",
        "    \n",
        "    # V√©rifier les fichiers de m√©tadonn√©es\n",
        "    metadata_files = [\"needle_summary.json\", \"defect_distribution.json\", \"split_assignment.json\"]\n",
        "    print(f\"\\\\nüìä Fichiers de m√©tadonn√©es:\")\n",
        "    for file_name in metadata_files:\n",
        "        file_path = os.path.join(base_path, \"metadata\", file_name)\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"‚úÖ {file_name}\")\n",
        "        else:\n",
        "            print(f\"‚ùå {file_name} manquant\")\n",
        "    \n",
        "    # V√©rifier data.yaml\n",
        "    yaml_path = os.path.join(base_path, \"yolo_format\", \"data.yaml\")\n",
        "    if os.path.exists(yaml_path):\n",
        "        print(f\"‚úÖ data.yaml\")\n",
        "    else:\n",
        "        print(f\"‚ùå data.yaml manquant\")\n",
        "\n",
        "print(\"‚úÖ Fonction de v√©rification d√©finie\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √âtape 6: V√©rifier les r√©sultats\n",
        "print(\"‚úÖ V√©rification des r√©sultats...\")\n",
        "check_directory_structure(OUTPUT_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Restructuration termin√©e !\n",
        "\n",
        "Votre dataset a √©t√© restructur√© avec succ√®s. Vous pouvez maintenant utiliser le notebook `yolo11_training_analysis.ipynb` pour l'entra√Ænement du mod√®le YOLO.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
